%%%%%%%%%%%%
%% Please rename this main.tex file and the output PDF to
%% [lastname_firstname_graduationyear]
%% before submission.
%%%%%%%%%%%%

\documentclass[12pt]{caltech_thesis}
\usepackage[hyphens]{url}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tabularx}
\usepackage{subcaption}
\usepackage{placeins}

\usepackage[acronym]{glossaries-extra}
\makeglossaries
\input{thesis/acronyms.tex} % <-- put acronyms.tex next to your main .tex

% Customize glossary spacing
\setlength{\glsdescwidth}{0.6\textwidth}
\renewcommand{\glsgroupskip}{2\baselineskip}
\renewcommand{\glspostdescription}{}
\renewcommand{\glsnamefont}[1]{\textbf{#1}}


\usepackage{todonotes}

%% Tentative: newtx for better-looking Times
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{newtxtext,newtxmath}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{microtype}
% Must use biblatex to produce the Published Contents and Contributions, per-chapter bibliography (if desired), etc.
\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}

% Name of your .bib file(s)
\addbibresource{example.bib}
\graphicspath{ {./media/} }


\begin{document}



% Do remember to remove the square bracket!
\title{\textbf{A probabilistic approach for adversarial perturbation of integer-constraint features for Jet-Flavour Tagging Algorithms in the CMS Experiment}}
\author{Martin Waletzko}

\group{Physics Institute III A}
\faculty{Faculty of Mathematics, Computer Science and Natural Science}      % Faculty name
\university{RWTH Aachen University}    % Institution name
%\unilogo{caltech.png}                                 % Institution logo
\copyyear{2025}  % Year (of graduation) on diploma
\copymonth{August}

\supervisor{Prof.\ Dr.\ rer.\ nat.\ Alexander Schmidt \\ Physics Institute III A}
\secondexaminer{Prof.\ Dr.\ rer.\ nat.\ Johannes Erdmann \\ Physics Institute III A}


\maketitle

% Abstract
\begin{abstract}

Adversarial attacks pose a significant challenge to the robustness of deep-learning models used in high-energy physics analyses. This thesis investigates the vulnerability of jet-flavour tagging algorithms within the Compact Muon Solenoid experiment to perturbations of specifically discrete input features. In addition to standard gradient-based methods such as Projected Gradient Descent (PGD), PIP is introduced – a probabilistic integer attack designed for discrete-valued physics inputs. The attack leverages instantaneous gradient information to assign feature-specific flip probabilities, enabling efficient perturbations without continuous relaxations. A combined PIP-PGD attack is further studied to target both feature domains simultaneously. Evaluation on DeepJet demonstrates that PIP can induce competitive degradation relative to PGD, with complementary effects when applied in conjunction. Adversarial training experiments show improved robustness to the targeted attack types, though with limited generalisation across unseen perturbations. These results highlight the importance of accounting for discrete-feature vulnerabilities in the development of resilient high energy physics machine learning models.

\vfill
\noindent\fbox{\parbox{0.95\textwidth}{
\textbf{Disclaimer}\\
This thesis acknowledges the use of various artificial intelligence technologies, including but not limited to language models and coding assistants. These tools were exclusively employed for the enhancement of the clarity and comprehensibility of the text. The final content, including all conclusions and interpretations, is the sole responsibility of the author.
}}

\end{abstract}

\begin{acknowledgements}

I would like to take this opportunity to express my sincere gratitude to all those who supported and assisted me throughout the preparation of this thesis.

My deepest thanks go to Prof. Dr. Alexander Schmidt for providing me with the opportunity to prepare this thesis under his supervision, and for his trust while I was new to deep learning. His guidance and encouragement made it possible to pursue this work on adversarial robustness and jet-flavour tagging to completion.

I am also grateful to Prof. Dr. Johannes Erdmann for kindly agreeing to serve as the second examiner of this thesis and for his constructive feedback.

Moreover, I would like to thank Ulrich Willemsen and Alexander Jung for their assistance, insightful discussions, and the supportive working environment. In particular, I am thankful for their patience, valuable ideas, and technical support.

Finally, I would like to thank my family and friends for their encouragement and careful proofreading

\end{acknowledgements}

\tableofcontents
\listoffigures
\listoftables
\glsaddall[types=\acronymtype]
\clearpage
{%
  \let\cleardoublepage\clearpage
  \printglossary[type=\acronymtype,nonumberlist,style=long]%
}
%\printglossary[type=\acronymtype,nonumberlist]

\mainmatter

% Introduction
\include{thesis/introduction.tex}

% Chapter 1
\include{thesis/standard_model.tex}

% Chapter 2
\include{thesis/machine_learning.tex}

% Chapter 3
\include{thesis/methodology.tex}

% Chapter 4
\include{thesis/adversarial_studies}

% Chapter 5
\include{thesis/conclusion}

\printbibliography

\appendix

% Exclude appendix figures from list of illustrations
\let\oldaddcontentsline\addcontentsline
\renewcommand{\addcontentsline}[3]{%
  \ifnum\pdfstrcmp{#2}{figure}=0
    \ifnum\value{chapter}>0
      % Don't add figures to list of illustrations in appendix
    \else
      \oldaddcontentsline{#1}{#2}{#3}%
    \fi
  \else
    \oldaddcontentsline{#1}{#2}{#3}%
  \fi
}

\chapter{Appendix}

\begin{table}[ht]
\centering
\caption{Evaluation metrics used to quantify model performance and perturbation impact.}
\begin{tabularx}{\textwidth}{@{} l X X @{}}
\toprule
\textbf{Metric} & \textbf{Definition / Calculation} & \textbf{Physical Interpretation} \\
\midrule
\textbf{ROC / AUC} &
The Receiver Operating Characteristic (ROC) curve plots the True Positive Rate (TPR, or sensitivity) against the False Positive Rate (FPR) across varying classification thresholds. The Area Under the Curve (AUC) is the integral of the ROC curve, ranging from 0.5 (random classifier) to 1.0 (perfect classifier). &
The ROC curve illustrates the trade-off between correctly identifying heavy-flavour jets (TPR) and mistakenly tagging background jets (FPR). A higher AUC indicates better model performance in distinguishing signal from background, critical for robust jet tagging. \\
\addlinespace
\textbf{\(\Delta\)AUC (AUC Drop)} &
Difference in the model’s Area Under the ROC Curve (AUC) between nominal (unperturbed) and adversarial datasets. Often reported as a percentage of the nominal AUC. &
Measures the loss of discriminative power for jet tagging. A larger drop means the adversarial attack significantly degrades the classifier’s ability to distinguish heavy-flavour jets from background (attack success). \\
\addlinespace
\textbf{Jensen–Shannon Distance (JSD)} &
The square root of the Jensen–Shannon divergence between the distribution of a given feature for nominal vs. attacked samples (see Equation~(\ref{eq:jsd})). Computed on each feature’s 1D histogram, excluding default/padding values. &
Quantifies the \emph{statistical difference} between original and perturbed feature distributions. Low JSD (near 0) indicates minimal change (stealthy), while high JSD reveals visible distribution shifts. \\
\hline
\end{tabularx}
\label{tab:evaluation_metrics}
\end{table}



\begin{figure}[h]
\centering
    \includegraphics[width=13cm]{media/output/intpgd_loss_validation.pdf}
    \caption{Training and validation loss for FGSM applied to the entire input spectrum training.}
    \label{fig:intpgd_train}
\end{figure}

\include{appendix/input_features}

\include{appendix/hist_intprob}

\include{appendix/hist_combined}


\end{document}
