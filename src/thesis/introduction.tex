\chapter{Introduction}

Modern particle physics is becoming increasingly dependent on Machine Learning (ML) for essential analytical tasks, ranging from event reconstruction to particle identification \cite{Stein2022}. One notable
application of this technology is jet flavour tagging, where algorithms aim to distinguish jets that originate
from different quark flavours. The identification of bottom-quark jets plays a central role in many precision measurements and searches for new physics at the Large Hadron Collider (LHC) \cite{PhysRevLett.121.121801}. However, the robustness of these models is critical. In the broader ML community, adversarial attacks — small, deliberately designed perturbations that can mislead a model — have been widely studied, particularly in computer vision \cite{goodfellow2015explainingharnessingadversarialexamples}. Their potential impact in particle physics remains under-explored though, especially in scenarios involving discrete-valued input features.

Jet-tagging algorithms such as DeepJet \cite{Bols_2020} process hundreds of features, including continuous detector observables and discrete quantities (e.g. counts and category identifiers). Most adversarial studies affect only continuous inputs, overlooking the unique behaviour and vulnerabilities of models when discrete inputs are perturbed. This gap offers an opportunity to probe robustness in a more comprehensive way.

This thesis addresses this challenge by introducing Probabilistic Integer Perturbation (PIP), an adversarial attack tailored to discrete features. PIP uses gradient information in a one-step heuristic to assign feature-specific probabilities for discrete changes, ensuring that all perturbations remain physically meaningful. This method is furthermore combined with the Projected Gradient Descent (PGD) attack \cite{madry2019deeplearningmodelsresistant}, targeting both continuous and discrete domains simultaneously and providing a broader evaluation of model vulnerabilities.

Empirically, this study uses the DeepJet architecture \cite{Bols_2020} trained on approximately ten million simulated jets across all major flavour categories. In addition to the susceptibility for perturbation of continuous values, the results show that DeepJet is vulnerable to degradation through discrete perturbations too. The combined Probabilistic Integer-Perturbed Projected Gradient Descent (PIP-PGD) attack amplifies this effect. Adversarial training with PIP-PGD attacks is presented as a solution, offering robustness in the respective regimes.

Although discrete perturbations do not directly correspond to realistic detector effects, they serve as a diagnostic tool to reveal model dependencies on discretised inputs. Insights that remain hidden in continuous-only studies are revealed through the use of these perturbations. The work presented here contributes to the development of a more complete understanding of adversarial robustness in High Energy Physics (HEP) machine learning and outlines approaches for developing models that are both accurate and resilient in demanding scientific applications.

\newpage
The thesis is structured as follows: Chapters 2–3 provide the background and baseline, with Chapter 2 reviewing the Standard Model, the LHC, and the CMS detector, and Chapter 3 surveying ML in HEP and adversarial ML while introducing the DeepJet tagger used throughout. Chapter 4 formalises the dataset, evaluation metrics, and threat model, and presents the first methodological contribution: Probabilistic Integer Perturbation (PIP), a gradient-guided attack for discrete inputs that preserves integer constraints and physical bounds, together with the joint PIP–PGD attack that perturbs discrete and continuous features in conjunction. Chapter 5 constitutes the main experimental contribution: a systematic robustness study on DeepJet quantifying attack severity (via Jensen–Shannon distance), classifier performance (ROC/AUC), iteration depth, and PIP sharpness—and a defence via adversarial training, demonstrating that training with PIP–PGD achieves the most balanced cross-robustness while maintaining strong nominal performance; additionally, we examine transferability and cross-robustness across attack types. Chapter 6 summarises the findings, discusses limitations, and outlines directions for robust, discrete-aware jet tagging in future CMS analyses.

Together, these results argue for discrete-aware robustness assessments in HEP ML and provide practical methods to develop taggers that are not only accurate but also resilient in demanding scientific applications.
